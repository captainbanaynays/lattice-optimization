## Overview
We will approach finding the minimum energy states of the $\text{Cu}_2\text{AgBiI}_6$ crystal using an evolutionary/generational algorithm that stratifies each generation into pools based on their space group. We then take representative samples of each pool decreasing in relative size to form the first generation, with a large percentage of the configurations in high-order space groups being analyzed down to a very small randomly selected fraction of the lower order space group configurations. Once a generation of ~$10^5$ configurations has been selected, it will be analyzed using VASP to determine optimal atomic positions and lattice energy for each configuration. The low-energy high space group configurations will determine the cutoff energy for which low-order configurations will be mutated to form the next generation. Mutation will be done using ((method TBD)). This process will be repeated until we can say with a high degree of certainty[^1] ($5\sigma$?) that we have the configuration(s) that represent the minimum of our dataset. 

## Reasoning
The idea behind this is that highly symmetric configurations in other site-disordered materials tend to generally result in low lattice energies in comparison to asymmetric configurations[^2], but do not necessarily contain the global minimum energy. Determining the space group of a configuration is a computationally simple task, and it should take a relatively small amount of time to index the entire set of configurations by their space grouping. It will also take a relatively small amount of time to run VASP on the very small number of highly symmetric configurations that we expect will produce some significantly low-energy configurations that may or may not be the global minimum. We can then take that small data set and figure out a reasonable upper bound for the lattice energy of the lower configurations that will then be selected and mutated. This will hopefully result in a much faster approach to the global minimum and more time generating configurations that we expect will be low-energy and a greater chance of finding the true global minim(um/a).

## Time estimation
Due to the electrical properties of the crystal, we will analyse a 3x3x1 unit cell section of the crystal. The upper limit of possible configurations that this area contains is as follows:
Per unit cell there are 12 copper/vacant sites and 3 Silver/bismuth/vacant sites, which means there are $2^{9 * 12} * 3^{9 * 3} = 2.475 * 10^{45}$ different possible configurations. 

If we just look at configurations with the specified stoichiometry, we can use a combinatoric method to figure out the number of configurations worth considering:
$${108 \choose 18} * \left[{27 \choose 9} + {18 \choose 9}\right] = 6.595 * 10^{26}$$
This is almost a 20 order of magnitude reduction in the number of configurations that are worth considering, however, this is still way too large to store any sort of information about the entire population, even 1 bit of information about each config requires a zettabyte of storage which is 1000 exabytes. Currently, estimates state that Google's total data storage capacity worldwide is in the tens of exabytes. We'll need to only deal with a small small fraction of the possible configurations at a time, in the order of single to 10 Gb of data. 

We will generate one config at a time, run it through spglib to determine its space group, and then place it into its proper bin in the first generation. We expect that this will be computationally trivial in comparison to the VASP runs, and should not be a problem to run until all bins are filled, regardless of what their initial determined size will be. Once a bin fills up, generated configurations in that space group will be skipped. We will then process the generation with VASP. We estimate that we can run ~50 instances in parallel, each taking about 5 minutes on the materials server. Roughly, this would give a runtime of 17 hours for a generation of size $10^5$.

We then select the `<percentage needed>` lowest energy configurations and mutate them according to the following procedure:
- Select 2+ parent configurations from the pool that was selected
- Index each of their filled copper, bismuth, and silver sites
- Generate 1+ children by iterating through those indices and randomly choosing which parent "passes down" that site occupancy to the child
- Add 0-5 random mutations: choose a random occupied site and a random site (of the correct atom type) and swap their contents

Including the parents, use this method to populate the proceeding generations, each of size $10^5$. Repeat until we get the same configuration output as the lowest possible energy 3 generations on a row. On the first run of the algorithm, this will basically be an arbitrary number of generations long... we can look at how the distributions converge up until this point and determine the rate, but the convergence rate based on the selectiveness, mutation procedure, and generation size will have to be experimentally determined. 

We will use the band gaps of the low-energy configurations and compare them to the experimental values published to verify our results as the lowest-energy configurations. We will also look at the last generation configs in reference to a composite first generation -- a "stand-in" for the population as a whole. How different is the low energy config that we've obtained from the population is a whole?

[^1]: What statistical model should we be expecting our data to fit? Does it work if we model the expected energy distribution across all spatial groups to the distribution that we are observing in the sample that we have analyzed? We won't be analyzing ~100% of the dataset so we will need to figure out how the selective sampling of the ML algorithm affects our certainty - look at diminishing returns / an asymptote in the minimum energy that we are seeing across configs as the generation increases

[^2]: Victor had a convincing chart that was shared in person, but I will need to look at the actual source paper.  